{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": "## 13.1 Creating windows of data\n\nWe’ll start off by creating the DataWindow class, which will allow us to format the data appropriately to be fed to our deep learning models. We’ll also add a plotting method to this class so that we can visualize the predictions and the actual values.\n\nBefore diving into the code and building the DataWindow class, however, it is important to understand why we must perform data windowing for deep learning. Deep learning models have a particular way of fitting on data, which we’ll explore in the next section. Then we’ll move on and implement the DataWindow class.\n\n## 13.1.1 Exploring how deep learning models are trained for time series forecasting\n\nIn the first half of this book, we fit statistical models, such as SARIMAX, on training sets and made predictions. We were, in reality, fitting a set of predefined functions of a certain order (p,d,q)(P,D,Q)m, and finding out which order resulted in the best fit.\n\nFor deep learning models, we do not have a set of functions to try. Instead, we let the neural network derive its own function such that when it takes the inputs, it generates the best predictions possible. To achieve that, we perform what is called data windowing.\n\nThis is a process in which we define a sequence of data points on our time series and define which are inputs and which are labels. That way, the deep learning model can fit on the inputs, generate predictions, compare them to the labels, and repeat this process until it cannot improve the accuracy of its predictions.\n\nLet’s walk through an example of data windowing. Our data window will use 24 hours of data to predict the next 24 hours. You probably wonder why are we using just 24 hours of data to generate predictions. After all, deep learning is data hungry and is used for large datasets. The key lies in the data window. A single window has 24 timesteps as input to generate an output of 24 timesteps. However, the entire training set is separated into multiple windows, meaning that we have many windows with inputs\nand labels, as shown in figure 13.1.\n\nIn figure 13.1 you can see the first 400 timesteps of our training set for traffic volume. Each data window consists of 24 input timesteps and 24 label timesteps (as shown in figure 13.2), giving us a total length of 48 timesteps. We can generate many data windows with the training set, so we are, in fact, leveraging this large quantity of data.\n\nAs you can see in figure 13.2, the data window’s total length is the sum of the lengths of each sequence. In this case, since we have 24 timesteps as input and 24 labels, the total length of the data window is 48 timesteps.\n\nYou might think that we are wasting a lot of training data, since in figure 13.2 timesteps 24 to 47 are labels. Are those never going to be used as inputs? Of course, they will be. The DataWindow class that we’ll implement in the next section generates data windows with inputs starting at t = 0. Then it will create another set of data windows, but this time starting at t = 1. Then it will start at t = 2. This goes on until it cannot have a sequence of 24 consecutive labels in the training set, as illustrated in figure 13.3.\n\nTo make computation more efficient, deep learning models are trained with batches. A batch is simply a collection of data windows that are fed to the model for training, as shown in figure 13.4.\n\nFigure 13.4 shows an example of a batch with a batch size of 32. That means that 32 data windows are grouped together and used to train the model. Of course, this is only one batch—the DataWindow class generates as many batches as possible with the given training set. In our case, we have a training set with 12,285 rows. If each batch has 32 data windows, that means that we will have 12285/32 = 384 batches.\n\nTraining the model on all 384 batches once is called one epoch. One epoch often does not result in an accurate model, so the model will train for as many epochs as necessary until it cannot improve the accuracy of its predictions.\n\nThe final important concept in data windowing for deep learning is shuffling. I mentioned in the very first chapter of this book that time series data cannot be shuffled. Time series data has an order, and that order must be kept, so why are we shuffling the data here?\n\nIn this context, shuffling occurs at the batch level, not inside the data window— the order of the time series itself is maintained within each data window. Each data window is independent of all others. Therefore, in a batch, we can shuffle the data windows and still keep the order of our time series, as shown in figure 13.5. Shuffling the data is not essential, but it is recommended as it tends to make more robust models\n\n### 13.1.2 Implementing the DataWindow class\n\nWe are now ready to implement the DataWindow class. This class has the advantage of being flexible, meaning that you can use it in a wide variety of scenarios to apply deep learning.\n\nThe class is based on the width of the input, the width of the label, and the shift. The width of the input is simply the number of timesteps that are fed into the model to make predictions. For example, given that we have hourly data in our dataset, if we feed the model with 24 hours of data to make a prediction, the input width is 24. If we feed only 12 hours of data, the input width is 12.\n\nThe label width is equivalent to the number of timesteps in the predictions. If we predict only one timestep, the label width is 1. If we predict a full day of data (with hourly data), the label width is 24.\n\nFinally, the shift is the number of timesteps separating the input and the predictions. If we predict the next timestep, the shift is 1. If we predict the next 24 hours (with hourly data), the shift is 24. Let’s visualize some windows of data to better understand these parameters. Figure 13.6 shows a window of data where the model predicts the next data point, given a single data point.\n\nNow let’s consider the situation where we feed 24 hours of data to the model in order to predict the next 24 hours. The data window in that situation is shown in figure 13.7.\n\nNow that you understand the concept of input width, label width, and shift, we can create the DataWindow class and define its initialization function in listing 13.1. The function will also take in the training, validation, and test sets, as the windows of data will come from our dataset. Finally, we’ll allow the target column to be specified."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": "import datetime\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras import Model, Sequential\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom tensorflow.keras.metrics import MeanAbsoluteError\n\nfrom tensorflow.keras.layers import Dense, Conv1D, LSTM, Lambda, Reshape, RNN, LSTMCell\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nplt.rcParams['figure.figsize'] = (10, 7.5)\nplt.rcParams['axes.grid'] = False\n\nprint(tf.__version__)\n\ntf.random.set_seed(42)\nnp.random.seed(42)\n\ntrain_df = pd.read_csv('./train.csv', index_col=0)\nval_df = pd.read_csv('./val.csv', index_col=0)\ntest_df = pd.read_csv('./test.csv', index_col=0)\n\nprint(train_df.shape, val_df.shape, test_df.shape)\n"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    },
    "trusted": true
   },
   "outputs": [],
   "source": "class DataWindow():\n    def __init__(self, input_width, label_width, shift, \n                 train_df=train_df, val_df=val_df, test_df=test_df, \n                 label_columns=None):\n        \n        self.train_df = train_df\n        self.val_df = val_df\n        self.test_df = test_df\n        \n        self.label_columns = label_columns\n        if label_columns is not None:\n            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n        \n        self.input_width = input_width\n        self.label_width = label_width\n        self.shift = shift\n        \n        self.total_window_size = input_width + shift\n        \n        self.input_slice = slice(0, input_width)\n        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n        \n        self.label_start = self.total_window_size - self.label_width\n        self.labels_slice = slice(self.label_start, None)\n        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n    \n    def split_to_inputs_labels(self, features):\n        inputs = features[:, self.input_slice, :]\n        labels = features[:, self.labels_slice, :]\n        if self.label_columns is not None:\n            labels = tf.stack(\n                [labels[:,:,self.column_indices[name]] for name in self.label_columns],\n                axis=-1\n            )\n        inputs.set_shape([None, self.input_width, None])\n        labels.set_shape([None, self.label_width, None])\n        \n        return inputs, labels\n    \n    def plot(self, model=None, plot_col='traffic_volume', max_subplots=3):\n        inputs, labels = self.sample_batch\n        \n        plt.figure(figsize=(12, 8))\n        plot_col_index = self.column_indices[plot_col]\n        max_n = min(max_subplots, len(inputs))\n        \n        for n in range(max_n):\n            plt.subplot(3, 1, n+1)\n            plt.ylabel(f'{plot_col} [scaled]')\n            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n                     label='Inputs', marker='.', zorder=-10)\n\n            if self.label_columns:\n              label_col_index = self.label_columns_indices.get(plot_col, None)\n            else:\n              label_col_index = plot_col_index\n\n            if label_col_index is None:\n              continue\n\n            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n                        edgecolors='k', marker='s', label='Labels', c='green', s=64)\n            if model is not None:\n              predictions = model(inputs)\n              plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n                          marker='X', edgecolors='k', label='Predictions',\n                          c='red', s=64)\n\n            if n == 0:\n              plt.legend()\n\n        plt.xlabel('Time (h)')\n        \n    def make_dataset(self, data):\n        data = np.array(data, dtype=np.float32)\n        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n            data=data,\n            targets=None,\n            sequence_length=self.total_window_size,\n            sequence_stride=1,\n            shuffle=True,\n            batch_size=32\n        )\n        \n        ds = ds.map(self.split_to_inputs_labels)\n        return ds\n    \n    @property\n    def train(self):\n        return self.make_dataset(self.train_df)\n    \n    @property\n    def val(self):\n        return self.make_dataset(self.val_df)\n    \n    @property\n    def test(self):\n        return self.make_dataset(self.test_df)\n    \n    @property\n    def sample_batch(self):\n        result = getattr(self, '_sample_batch', None)\n        if result is None:\n            result = next(iter(self.train))\n            self._sample_batch = result\n        return result\n    "
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": "In listing 13.1 you can see that the initialization function basically assigns the variables and manages the indices of the inputs and the labels. Our next step is to split our window between inputs and labels, so that our models can make predictions based on the inputs and measure an error metric against the labels. The following split_to_inputs_labels function is defined within the DataWindow class.\n\nThe split_to_inputs_labels function will separate the big data window into two windows: one for the inputs and the other for the labels.\n\n```\n    def split_to_inputs_labels(self, features):\n        inputs = features[:, self.input_slice, :]\n        labels = features[:, self.labels_slice, :]\n        if self.label_columns is not None:\n            labels = tf.stack(\n                [labels[:,:,self.column_indices[name]] for name in self.label_columns],\n                axis=-1\n            )\n        inputs.set_shape([None, self.input_width, None])\n        labels.set_shape([None, self.label_width, None])\n        \n        return inputs, labels\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": "Next we’ll define a function to plot the input data, the predictions, and the actual values. Since we will be working with many time windows, we’ll show only the plot of three time windows, but this parameter can easily be changed. Also, the default label will be traffic volume, but we can change that by specifying any column we choose. Again, this function should be included in the DataWindow class.\n\n~~~\n    def plot(self, model=None, plot_col='traffic_volume', max_subplots=3):\n        inputs, labels = self.sample_batch\n        \n        plt.figure(figsize=(12, 8))\n        plot_col_index = self.column_indices[plot_col]\n        max_n = min(max_subplots, len(inputs))\n        \n        for n in range(max_n):\n            plt.subplot(3, 1, n+1)\n            plt.ylabel(f'{plot_col} [scaled]')\n            plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n                     label='Inputs', marker='.', zorder=-10)\n\n            if self.label_columns:\n              label_col_index = self.label_columns_indices.get(plot_col, None)\n            else:\n              label_col_index = plot_col_index\n\n            if label_col_index is None:\n              continue\n\n            plt.scatter(self.label_indices, labels[n, :, label_col_index],\n                        edgecolors='k', marker='s', label='Labels', c='green', s=64)\n            if model is not None:\n              predictions = model(inputs)\n              plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n                          marker='X', edgecolors='k', label='Predictions',\n                          c='red', s=64)\n\n            if n == 0:\n              plt.legend()\n\n        plt.xlabel('Time (h)')\n~~~"
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": "We are almost done building the DataWindow class. The last main piece of logic will format our dataset into tensors so that they can be fed to our deep learning models. TensorFlow comes with a very handy function called timeseries_dataset_from_array, which creates a dataset of sliding windows, given an array.\n\n```\n    def make_dataset(self, data):\n        data = np.array(data, dtype=np.float32)\n        ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n            data=data,\n            targets=None,\n            sequence_length=self.total_window_size,\n            sequence_stride=1,\n            shuffle=True,\n            batch_size=32\n        )\n        \n        ds = ds.map(self.split_to_inputs_labels)\n        return ds\n    \n    @property\n    def train(self):\n        return self.make_dataset(self.train_df)\n    \n    @property\n    def val(self):\n        return self.make_dataset(self.val_df)\n    \n    @property\n    def test(self):\n        return self.make_dataset(self.test_df)\n    \n    @property\n    def sample_batch(self):\n        result = getattr(self, '_sample_batch', None)\n        if result is None:\n            result = next(iter(self.train))\n            self._sample_batch = result\n        return result\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "For now, the DataWindow class might seem a bit abstract, but we will soon use it to apply baseline models. We will be using this class in all the chapters in this deep learning part of the book, so you will gradually tame this code and appreciate how easy it is to test different deep learning architectures.\n\n## 13.2 Applying baseline models\n\nWith the DataWindow class complete, we are ready to use it. We will apply baseline models as single-step, multi-step, and multi-output models. You will see that their implementation is similar and incredibly simple when we have the right data windows.\n\nRecall that a baseline is used as a benchmark to evaluate more complex models. A model is performant if it compares favorably to another, so building a baseline is an important step in modeling.\n\n### 13.2.1 Single-step baseline model\n\nWe’ll first implement a single-step model as a baseline. In a single-step model, the input is one timestep and the output is the prediction of the next timestep.\n\nThe first step is to generate a window of data. Since we are defining a single-step model, the input width is 1, the label width is 1, and the shift is also 1, since the model predicts the next timestep. Our target variable is the volume of traffic.\n\nFor plotting purposes, we’ll also define a wider window so we can visualize many predictions of our model. Otherwise, we could only visualize one input data point and one output prediction, which is not very interesting."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "single_step_window = DataWindow(input_width=1, label_width=1, shift=1, label_columns=['traffic_volume']) \nwide_window = DataWindow(input_width=24, label_width=24, shift=1, label_columns=['traffic_volume'])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "In this situation, the simplest prediction we can make is the last observed value. Basically, the prediction is simply the input data point. This is implemented by the class Baseline. As you can see in the following listing, the Baseline class can also be used for a multi-output model. For now, we’ll solely focus on a single-step model."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "class Baseline(Model):\n    def __init__(self, label_index=None):\n        super().__init__()\n        self.label_index = label_index\n        \n    def call(self, inputs):\n        if self.label_index is None:\n            return inputs\n        \n        elif isinstance(self.label_index, list):\n            tensors = []\n            for index in self.label_index:\n                result = inputs[:, :, index]\n                result = result[:, :, tf.newaxis]\n                tensors.append(result)\n            return tf.concat(tensors, axis=-1)\n        \n        result = inputs[:, :, self.label_index]\n        return result[:,:,tf.newaxis]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "With the class defined, we can now initialize the model and compile it to generate predictions. To do so, we’ll find the index of our target column, traffic_volume, and pass it in to Baseline. Note that TensorFlow requires us to provide a loss function and a metric of evaluation. In this case, and throughout the deep learning chapters, we’ll use the mean squared error (MSE) as a loss function—it penalizes large errors, and it generally yields well-fitted models. For the evaluation metric, we’ll use the mean absolute error (MAE) for its ease of interpretation."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "column_indices = {name: i for i, name in enumerate(train_df.columns)}\n\nbaseline_last = Baseline(label_index=column_indices['traffic_volume'])\n\nbaseline_last.compile(loss=MeanSquaredError(), metrics=[MeanAbsoluteError()])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We’ll now evaluate the performance of our baseline on both the validation and test sets.\n\nModels built with TensorFlow conveniently come with the evaluate method, which allows us to compare the predictions to the actual values and calculate the error metric."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "val_performance = {}\nperformance = {}\n\nval_performance['Baseline - Last'] = baseline_last.evaluate(single_step_window.val)\nperformance['Baseline - Last'] = baseline_last.evaluate(single_step_window.test, verbose=0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Great, we have successfully built a baseline that predicts the last known value and evaluated it. We can visualize the predictions using the plot method of the DataWindow class. Remember to use the wide_window to see more than just two data points.\n\nIn figure 13.9 the labels are squares and the predictions are crosses. The crosses at each timestep are simply the last known value, meaning that we have a baseline that functions as expected. Your plot may differ from figure 13.9, as the cached sample batch changes every time a data window is initialized."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "wide_window.plot(baseline_last)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We can optionally print the MAE of our baseline on the test set. \n\nThis returns an MAE of 0.081. More complex models should perform better than the baseline, resulting in a smaller MAE."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "print(performance['Baseline - Last'][1])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "### 13.2.2 Multi-step baseline models\n\nIn the previous section, we built a single-step baseline model that simply predicted the last known value. For multi-step models, we’ll predict more than one timestep into the future. In this case, we’ll forecast the traffic volume for the next 24 hours of data given an input of 24 hours.\n\nAgain, the first step is to generate the appropriate window of data. Because we wish to predict 24 timesteps into the future with an input of 24 hours, the input width is 24, the label width is 24, and the shift is also 24."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "multi_window = DataWindow(input_width=24, label_width=24, shift=24, label_columns=['traffic_volume'])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "With the data window generated, we can now focus on implementing the baseline models. In this situation, there are two reasonable baselines:\n- Predict the last known value for the next 24 timesteps.\n- Predict the last 24 timesteps for the next 24 timesteps.\n\nWith that in mind, let’s implement the first baseline, where we’ll simply repeat the last known value over the next 24 timesteps.\n\n**PREDICTING THE LAST KNOWN VALUE**\n\nTo predict the last known value, we’ll define a MultiStepLastBaseline class that simply takes in the input and repeats the last value of the input sequence over 24 timesteps. This acts as the prediction of the model."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "class MultiStepLastBaseline(Model):\n    def __init__(self, label_index=None):\n        super().__init__()\n        self.label_index = label_index\n        \n    def call(self, inputs):\n        if self.label_index is None:\n            return tf.tile(inputs[:, -1:, :], [1, 24, 1])\n        return tf.tile(inputs[:, -1:, self.label_index:], [1, 24, 1])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Next we’ll initialize the class and specify the target column. We’ll then repeat the same steps as in the previous section, compiling the model and evaluating it on the validation set and test set."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "ms_baseline_last = MultiStepLastBaseline(label_index=column_indices['traffic_volume'])\n\nms_baseline_last.compile(loss=MeanSquaredError(), metrics=[MeanAbsoluteError()])\n\nms_val_performance = {}\nms_performance = {}\n\nms_val_performance['Baseline - Last'] = ms_baseline_last.evaluate(multi_window.val)\nms_performance['Baseline - Last'] = ms_baseline_last.evaluate(multi_window.test, verbose=0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We can now visualize the predictions using the plot method of DataWindow."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "multi_window.plot(ms_baseline_last)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Again, we can optionally print the baseline’s MAE. From figure 13.10, we can expect it to be fairly high, since there is a large discrepancy between the labels and the predictions."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "print(ms_performance['Baseline - Last'][1])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "This gives an MAE of 0.347. Now let’s see if we can build a better baseline by simply repeating the input sequence."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "class RepeatBaseline(Model):\n    def __init__(self, label_index=None):\n        super().__init__()\n        self.label_index = label_index\n        \n    def call(self, inputs):\n        return inputs[:, :, self.label_index:]"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Now we can initialize the baseline model and generate predictions. Note that the loss function and evaluation metric remain the same."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "ms_baseline_repeat = RepeatBaseline(label_index=column_indices['traffic_volume'])\n\nms_baseline_repeat.compile(loss=MeanSquaredError(), metrics=[MeanAbsoluteError()])\n\nms_val_performance['Baseline - Repeat'] = ms_baseline_repeat.evaluate(multi_window.val)\nms_performance['Baseline - Repeat'] = ms_baseline_repeat.evaluate(multi_window.test, verbose=0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Next we can visualize the predictions. The result is shown in figure 13.11.\n\nThis baseline performs well. This is to be expected, since we identified daily seasonality in the previous chapter. This baseline is the equivalent to predicting the last known season."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "multi_window.plot(ms_baseline_repeat)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Again, we can print the MAE on the test set to verify that we indeed have a better baseline than simply predicting the last known value."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "print(ms_performance['Baseline - Repeat'][1])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "This gives an MAE of 0.341, which is lower than the MAE obtained by predicting the last known value. We have therefore successfully built a better baseline.\n\n### 13.2.3 Multi-output baseline model\n\nThe final type of model we’ll cover is the multi-output model. In this situation, we wish to predict the traffic volume and the temperature for the next timestep using a single input data point. Essentially, we’re applying the single-step model on both the traffic volume and temperature, making it a multi-output model.\n\nAgain, we’ll start off by defining the window of data, but here we’ll define two windows: One for training and the other for visualization. Since the model takes in one data point and outputs one prediction, we want to initialize a wide window of data to visualize many predictions over many timesteps."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "mo_single_step_window = DataWindow(input_width=1, label_width=1, shift=1, label_columns=['temp','traffic_volume']) \nmo_wide_window = DataWindow(input_width=24, label_width=24, shift=1, label_columns=['temp','traffic_volume'])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Then we’ll use the Baseline class that we defined for the single-step model. Recall that this class can output the last known value for a list of targets."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "print(column_indices['traffic_volume'])\nprint(column_indices['temp'])"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "mo_baseline_last = Baseline(label_index=[0, 2])\n\nmo_baseline_last.compile(loss=MeanSquaredError(), metrics=[MeanAbsoluteError()])\n\nmo_val_performance = {}\nmo_performance = {}\n\nmo_val_performance['Baseline - Last'] = mo_baseline_last.evaluate(mo_wide_window.val)\nmo_performance['Baseline - Last'] = mo_baseline_last.evaluate(mo_wide_window.test, verbose=0)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Finally, we can visualize the predictions against the actual values. By default, our plot method will show the traffic volume on the y-axis, allowing us to quickly display one of our targets."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": "mo_wide_window.plot(mo_baseline_last)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Figure 13.12 does not show anything surprising, as we already saw these results when we built a single-step baseline model. The particularity of the multi-output model is that we also have predictions for the temperature. Of course, we can also visualize the predictions for the temperature by specifying the target in the plot method. "
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "mo_wide_window.plot(model=mo_baseline_last, plot_col='temp')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "Again, we can print the MAE of our baseline model."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": "print(mo_performance['Baseline - Last'])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "We obtain an MAE of 0.047 on the test set. In the next chapter, we’ll start building\nmore complex models, and they should result in a lower MAE, as they will be trained\nto fit the data."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}